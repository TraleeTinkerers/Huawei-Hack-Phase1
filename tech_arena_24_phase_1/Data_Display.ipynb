{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_problem_data, load_solution\n",
    "from evaluation import evaluation_function, get_actual_demand\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "demand, datacenters, servers, selling_prices = load_problem_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>latency_sensitivity</th>\n",
       "      <th>time_step</th>\n",
       "      <th>server_generation</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>2571</td>\n",
       "      <td>17471</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>5860</td>\n",
       "      <td>36140</td>\n",
       "      <td>6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>107</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>7285</td>\n",
       "      <td>48584</td>\n",
       "      <td>7361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>167</td>\n",
       "      <td>GPU.S3</td>\n",
       "      <td>1375</td>\n",
       "      <td>5274</td>\n",
       "      <td>8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>168</td>\n",
       "      <td>CPU.S3</td>\n",
       "      <td>88021</td>\n",
       "      <td>15649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>168</td>\n",
       "      <td>CPU.S4</td>\n",
       "      <td>662906</td>\n",
       "      <td>911679</td>\n",
       "      <td>169388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>168</td>\n",
       "      <td>GPU.S2</td>\n",
       "      <td>564</td>\n",
       "      <td>51</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>168</td>\n",
       "      <td>GPU.S3</td>\n",
       "      <td>652</td>\n",
       "      <td>4873</td>\n",
       "      <td>6868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "latency_sensitivity  time_step server_generation    high     low  medium\n",
       "0                            1            CPU.S1    2571   17471    2512\n",
       "1                            1            GPU.S1      43      13       7\n",
       "2                            2            CPU.S1    5860   36140    6397\n",
       "3                            2            GPU.S1     107      25      21\n",
       "4                            3            CPU.S1    7285   48584    7361\n",
       "..                         ...               ...     ...     ...     ...\n",
       "667                        167            GPU.S3    1375    5274    8312\n",
       "668                        168            CPU.S3   88021   15649       0\n",
       "669                        168            CPU.S4  662906  911679  169388\n",
       "670                        168            GPU.S2     564      51     990\n",
       "671                        168            GPU.S3     652    4873    6868\n",
       "\n",
       "[672 rows x 5 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3163)\n",
    "actual_demand = get_actual_demand(demand)\n",
    "actual_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_demand.to_csv(\"actual_demand.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming `actual_demand` is the DataFrame that has been obtained using get_actual_demand(demand)\n",
    "\n",
    "# Step 1: Filter the DataFrame to include all latency sensitivities\n",
    "# No need to filter here, we will process all columns (high, medium, low)\n",
    "\n",
    "# Step 2: Prepare the result list with the correct format\n",
    "result = []\n",
    "\n",
    "# Iterate over each time_step to aggregate demands for high, medium, and low latency\n",
    "for time_step in actual_demand[\"time_step\"].unique():\n",
    "    # Filter data for the current time_step\n",
    "    time_step_data = actual_demand[actual_demand[\"time_step\"] == time_step]\n",
    "\n",
    "    # Prepare dictionaries for each latency sensitivity\n",
    "    dc_demands = {\n",
    "        \"DC1\": {},\n",
    "        \"DC2\": {},\n",
    "        \"DC3\": {},\n",
    "        \"DC4\": {},\n",
    "    }\n",
    "\n",
    "    for _, row in time_step_data.iterrows():\n",
    "        server = row[\"server_generation\"]\n",
    "\n",
    "        # Distribute high demand\n",
    "        if row[\"high\"] > 0:\n",
    "            high_demand_dc3 = int(row[\"high\"] * 0.4588)\n",
    "            high_demand_dc4 = int(row[\"high\"] - high_demand_dc3)\n",
    "            dc_demands[\"DC3\"][server] = high_demand_dc3\n",
    "            dc_demands[\"DC4\"][server] = high_demand_dc4\n",
    "\n",
    "        # Assign medium demand to DC1\n",
    "        if row[\"low\"] > 0:\n",
    "            dc_demands[\"DC1\"][server] = int(row[\"low\"])\n",
    "\n",
    "        # Assign low demand to DC2\n",
    "        if row[\"medium\"] > 0:\n",
    "            dc_demands[\"DC2\"][server] = int(row[\"medium\"])\n",
    "\n",
    "    # Append the formatted dictionary to the result list\n",
    "    result.append(\n",
    "        {\n",
    "            \"time_step\": int(time_step),\n",
    "            \"DC1\": dc_demands[\"DC1\"],\n",
    "            \"DC2\": dc_demands[\"DC2\"],\n",
    "            \"DC3\": dc_demands[\"DC3\"],\n",
    "            \"DC4\": dc_demands[\"DC4\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Step 3: Convert the result list to JSON and save to a file\n",
    "with open(\"demand_by_time_step_and_data_center.json\", \"w\") as json_file:\n",
    "    json.dump(result, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>latency_sensitivity</th>\n",
       "      <th>time_step</th>\n",
       "      <th>server_generation</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>19722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>27524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>167</td>\n",
       "      <td>GPU.S3</td>\n",
       "      <td>8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>168</td>\n",
       "      <td>CPU.S3</td>\n",
       "      <td>279723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>168</td>\n",
       "      <td>CPU.S4</td>\n",
       "      <td>282980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>168</td>\n",
       "      <td>GPU.S2</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>168</td>\n",
       "      <td>GPU.S3</td>\n",
       "      <td>9608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "latency_sensitivity  time_step server_generation  medium\n",
       "0                            1            CPU.S1    9235\n",
       "1                            1            GPU.S1       0\n",
       "2                            2            CPU.S1   19722\n",
       "3                            2            GPU.S1       2\n",
       "4                            3            CPU.S1   27524\n",
       "..                         ...               ...     ...\n",
       "667                        167            GPU.S3    8769\n",
       "668                        168            CPU.S3  279723\n",
       "669                        168            CPU.S4  282980\n",
       "670                        168            GPU.S2    1166\n",
       "671                        168            GPU.S3    9608\n",
       "\n",
       "[672 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming `actual_demand` is the DataFrame that has been obtained using get_actual_demand(demand)\n",
    "\n",
    "# Step 1: Filter the DataFrame to include only the 'medium' latency sensitivity\n",
    "medium_demands = actual_demand[[\"time_step\", \"server_generation\", \"medium\"]]\n",
    "display(medium_demands)\n",
    "\n",
    "# Step 2: Aggregate the demand per time_step and server_generation\n",
    "# This will sum up the demands across all server types for each time_step\n",
    "demand_per_time_step = (\n",
    "    medium_demands.groupby([\"time_step\", \"server_generation\"])[\"medium\"]\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Step 3: Prepare the result list with the correct format\n",
    "result = []\n",
    "\n",
    "# Iterate over each time_step and prepare the data for JSON output\n",
    "for time_step in demand_per_time_step.index:\n",
    "    # Extract the demand for the current time_step\n",
    "    demand_data = demand_per_time_step.loc[time_step]\n",
    "\n",
    "    # Create the demand dictionary, only including servers with non-zero demand\n",
    "    demand_dict = {\n",
    "        server: int(demand_data[server])\n",
    "        for server in demand_data.index\n",
    "        if demand_data[server] > 0\n",
    "    }\n",
    "\n",
    "    # Append the formatted dictionary to the result list\n",
    "    result.append({\"time_step\": int(time_step), \"demand\": demand_dict})\n",
    "\n",
    "# Step 4: Convert the result list to JSON and save to a file\n",
    "with open(\"demand_by_time_step.json\", \"w\") as json_file:\n",
    "    json.dump(result, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming `actual_demand` is the DataFrame that has been obtained using get_actual_demand(demand)\n",
    "\n",
    "# Step 1: Filter the DataFrame to include all latency sensitivities\n",
    "# No need to filter here, we will process all columns (high, medium, low)\n",
    "\n",
    "# Step 2: Prepare the result list with the correct format\n",
    "result = []\n",
    "\n",
    "# Iterate over each time_step to aggregate demands for high, medium, and low latency\n",
    "for time_step in actual_demand[\"time_step\"].unique():\n",
    "    # Filter data for the current time_step\n",
    "    time_step_data = actual_demand[actual_demand[\"time_step\"] == time_step]\n",
    "\n",
    "    # Prepare dictionaries for each latency sensitivity\n",
    "    high_demand = {}\n",
    "    medium_demand = {}\n",
    "    low_demand = {}\n",
    "\n",
    "    for _, row in time_step_data.iterrows():\n",
    "        server = row[\"server_generation\"]\n",
    "\n",
    "        # Populate demand dictionaries\n",
    "        if row[\"high\"] > 0:\n",
    "            high_demand[server] = int(row[\"high\"])\n",
    "        if row[\"medium\"] > 0:\n",
    "            medium_demand[server] = int(row[\"medium\"])\n",
    "        if row[\"low\"] > 0:\n",
    "            low_demand[server] = int(row[\"low\"])\n",
    "\n",
    "    # Append the formatted dictionary to the result list\n",
    "    result.append(\n",
    "        {\n",
    "            \"time_step\": int(time_step),\n",
    "            \"high demand\": high_demand,\n",
    "            \"medium demand\": medium_demand,\n",
    "            \"low demand\": low_demand,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Step 3: Convert the result list to JSON and save to a file\n",
    "with open(\"demand_by_time_step_and_latency_sensitivity.json\", \"w\") as json_file:\n",
    "    json.dump(result, json_file, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>latency_sensitivity</th>\n",
       "      <th>server_generation</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "latency_sensitivity server_generation  medium\n",
       "0                              CPU.S1    9235\n",
       "1                              GPU.S1       0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_by_time_step_and_sensitivity(df, time_step, sensitivity):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame by the given time_step and latency_sensitivity level.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the actual demand data.\n",
    "        time_step (int): The time_step value to filter by.\n",
    "        sensitivity (str): The latency sensitivity level to filter by ('low', 'high', 'medium').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered DataFrame containing only the specified latency sensitivity level.\n",
    "    \"\"\"\n",
    "    # Filter by time_step\n",
    "    filtered_df = df[df[\"time_step\"] == time_step]\n",
    "\n",
    "    # Select only the columns that match the sensitivity\n",
    "    if sensitivity in [\"low\", \"high\", \"medium\"]:\n",
    "        filtered_df = filtered_df[[\"server_generation\", sensitivity]]\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming actual_demand is your DataFrame\n",
    "chosen_time_step = 1\n",
    "chosen_sensitivity = \"medium\"\n",
    "actual_demand_filter_by_time_step_and_sensitivity = filter_by_time_step_and_sensitivity(\n",
    "    actual_demand, chosen_time_step, chosen_sensitivity\n",
    ")\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "actual_demand_filter_by_time_step_and_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All servers are used in low latency sensitivity.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your list of all possible servers\n",
    "all_servers = {\"CPU.S1\", \"CPU.S2\", \"CPU.S3\", \"CPU.S4\", \"GPU.S1\", \"GPU.S2\", \"GPU.S3\"}\n",
    "\n",
    "# Filter rows where the \"low\" column is greater than zero\n",
    "low_latency_servers = actual_demand[actual_demand[\"low\"] > 0][\n",
    "    \"server_generation\"\n",
    "].unique()\n",
    "\n",
    "# Convert the result to a set\n",
    "low_latency_servers_set = set(low_latency_servers)\n",
    "\n",
    "# Check if all servers are used in low latency sensitivity\n",
    "all_servers_used_in_low = all_servers.issubset(low_latency_servers_set)\n",
    "\n",
    "if all_servers_used_in_low:\n",
    "    print(\"All servers are used in low latency sensitivity.\")\n",
    "else:\n",
    "    print(\"Not all servers are used in low latency sensitivity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slots capacity for DC1(Low):  25245\n"
     ]
    }
   ],
   "source": [
    "data_center = pd.read_csv('./data/datacenters.csv')\n",
    "data_center\n",
    "\n",
    "filtered_dc = data_center[data_center['latency_sensitivity'] == 'low']\n",
    "DC1_slot_capacity = filtered_dc[\"slots_capacity\"].values[0]\n",
    "print(\"Slots capacity for DC1(Low): \", filtered_dc[\"slots_capacity\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>server_used</th>\n",
       "      <th>CPU.S1</th>\n",
       "      <th>CPU.S2</th>\n",
       "      <th>CPU.S3</th>\n",
       "      <th>CPU.S4</th>\n",
       "      <th>GPU.S1</th>\n",
       "      <th>GPU.S2</th>\n",
       "      <th>GPU.S3</th>\n",
       "      <th>CPU.S1_needed</th>\n",
       "      <th>CPU.S2_needed</th>\n",
       "      <th>CPU.S3_needed</th>\n",
       "      <th>CPU.S4_needed</th>\n",
       "      <th>GPU.S1_needed</th>\n",
       "      <th>GPU.S2_needed</th>\n",
       "      <th>GPU.S3_needed</th>\n",
       "      <th>slots_needed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>37118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215588</td>\n",
       "      <td>204116</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>7082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>10262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226351</td>\n",
       "      <td>247261</td>\n",
       "      <td>0</td>\n",
       "      <td>1191</td>\n",
       "      <td>7096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>11010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247293</td>\n",
       "      <td>220712</td>\n",
       "      <td>0</td>\n",
       "      <td>1162</td>\n",
       "      <td>7776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2061.0</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>11354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>259962</td>\n",
       "      <td>285805</td>\n",
       "      <td>0</td>\n",
       "      <td>1186</td>\n",
       "      <td>8769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>1787.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>12892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279723</td>\n",
       "      <td>282980</td>\n",
       "      <td>0</td>\n",
       "      <td>1166</td>\n",
       "      <td>9608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2332.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>13590.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time_step  server_used  CPU.S1  CPU.S2  CPU.S3  CPU.S4  GPU.S1  GPU.S2  \\\n",
       "0            1            2    9235       0       0       0       0       0   \n",
       "1            2            2   19722       0       0       0       2       0   \n",
       "2            3            2   27524       0       0       0       0       0   \n",
       "3            4            2   37118       0       0       0       3       0   \n",
       "4            5            2   52385       0       0       0      13       0   \n",
       "..         ...          ...     ...     ...     ...     ...     ...     ...   \n",
       "163        164            4       0       0  215588  204116       0    1138   \n",
       "164        165            4       0       0  226351  247261       0    1191   \n",
       "165        166            4       0       0  247293  220712       0    1162   \n",
       "166        167            4       0       0  259962  285805       0    1186   \n",
       "167        168            4       0       0  279723  282980       0    1166   \n",
       "\n",
       "     GPU.S3  CPU.S1_needed  CPU.S2_needed  CPU.S3_needed  CPU.S4_needed  \\\n",
       "0         0          154.0            0.0            0.0            0.0   \n",
       "1         0          329.0            0.0            0.0            0.0   \n",
       "2         0          459.0            0.0            0.0            0.0   \n",
       "3         0          619.0            0.0            0.0            0.0   \n",
       "4         0          874.0            0.0            0.0            0.0   \n",
       "..      ...            ...            ...            ...            ...   \n",
       "163    7082            0.0            0.0         1797.0         1276.0   \n",
       "164    7096            0.0            0.0         1887.0         1546.0   \n",
       "165    7776            0.0            0.0         2061.0         1380.0   \n",
       "166    8769            0.0            0.0         2167.0         1787.0   \n",
       "167    9608            0.0            0.0         2332.0         1769.0   \n",
       "\n",
       "     GPU.S1_needed  GPU.S2_needed  GPU.S3_needed  slots_needed  \n",
       "0              0.0            0.0            0.0         308.0  \n",
       "1              1.0            0.0            0.0         662.0  \n",
       "2              0.0            0.0            0.0         918.0  \n",
       "3              1.0            0.0            0.0        1242.0  \n",
       "4              2.0            0.0            0.0        1756.0  \n",
       "..             ...            ...            ...           ...  \n",
       "163            0.0          143.0          886.0       10262.0  \n",
       "164            0.0          149.0          887.0       11010.0  \n",
       "165            0.0          146.0          972.0       11354.0  \n",
       "166            0.0          149.0         1097.0       12892.0  \n",
       "167            0.0          146.0         1201.0       13590.0  \n",
       "\n",
       "[168 rows x 17 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `actual_demand` is your initial DataFrame\n",
    "\n",
    "# Step 1: Process Low Demands\n",
    "low_demands = actual_demand[[\"time_step\", \"server_generation\", \"medium\"]]\n",
    "\n",
    "# Calculate server usage\n",
    "server_usage = (\n",
    "    low_demands.groupby(\"time_step\")[\"server_generation\"].nunique().reset_index()\n",
    ")\n",
    "server_usage.columns = [\"time_step\", \"server_used\"]\n",
    "\n",
    "# Aggregate demand per time_step\n",
    "demand_per_time_step = (\n",
    "    low_demands.groupby([\"time_step\", \"server_generation\"])[\"medium\"]\n",
    "    .sum()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Merge the two DataFrames\n",
    "result = pd.merge(server_usage, demand_per_time_step, on=\"time_step\")\n",
    "\n",
    "# Step 2: Load Server Capacities\n",
    "server_capacity = pd.read_csv(\"./data/servers.csv\")\n",
    "\n",
    "# Convert server capacities to a dictionary for easy lookup\n",
    "server_capacity_dict = dict(\n",
    "    zip(server_capacity[\"server_generation\"], server_capacity[\"capacity\"])\n",
    ")\n",
    "\n",
    "# Calculate how many of each server is needed for each time_step\n",
    "for server in server_capacity_dict.keys():\n",
    "    result[f\"{server}_needed\"] = (result[server] / server_capacity_dict[server]).apply(\n",
    "        np.ceil\n",
    "    )\n",
    "\n",
    "# Fill NaN values with 0 (in case some servers weren't used at all)\n",
    "result = result.fillna(0)\n",
    "\n",
    "# Step 3: Define Slot Capacities and Calculate Slots Needed\n",
    "cpu_slot_capacity = 2\n",
    "gpu_slot_capacity = 4\n",
    "\n",
    "# Calculate total CPU slots needed\n",
    "cpu_columns = [col for col in result.columns if col.startswith(\"CPU\") and col.endswith(\"needed\")]\n",
    "result[\"CPU_slots_needed\"] = (\n",
    "    result[cpu_columns].sum(axis=1) * cpu_slot_capacity\n",
    ").apply(np.ceil)\n",
    "\n",
    "# Calculate total GPU slots needed\n",
    "gpu_columns = [\n",
    "    col for col in result.columns if col.startswith(\"GPU\") and col.endswith(\"needed\")\n",
    "]\n",
    "result[\"GPU_slots_needed\"] = (\n",
    "    result[gpu_columns].sum(axis=1) * gpu_slot_capacity\n",
    ").apply(np.ceil)\n",
    "\n",
    "# Total slots needed\n",
    "result[\"slots_needed\"] = result[\"CPU_slots_needed\"] + result[\"GPU_slots_needed\"]\n",
    "\n",
    "# Drop intermediate columns if desired\n",
    "result = result.drop(columns=[\"CPU_slots_needed\", \"GPU_slots_needed\"])\n",
    "\n",
    "# Review the final DataFrame\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
